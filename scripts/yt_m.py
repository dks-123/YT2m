import os
import re
import httpx
import paramiko
import json
import time
import random
import base64
from urllib.parse import urlparse, unquote
from datetime import datetime, timedelta

yt_info_path = "yt_info.txt"
output_dir = "output"
cookies_path = os.path.join(os.getcwd(), "cookies.txt")
API_KEY = os.getenv("YT_API_KEY", "")
if not API_KEY:
    print("âŒ ç’°å¢ƒè®Šæ•¸ YT_API_KEY æœªè¨­ç½®ï¼Œæ”¹ç”¨ HTML è§£æ")

SF_L = os.getenv("SF_L", "")
if not SF_L:
    print("âŒ ç’°å¢ƒè®Šæ•¸ SF_L æœªè¨­ç½®")
    exit(1)

parsed_url = urlparse(SF_L)
SFTP_HOST = parsed_url.hostname
SFTP_PORT = parsed_url.port if parsed_url.port else 22
SFTP_USER = parsed_url.username
SFTP_PASSWORD = parsed_url.password
SFTP_REMOTE_DIR = parsed_url.path if parsed_url.path else "/"

os.makedirs(output_dir, exist_ok=True)

# æ“´å±•çš„ User-Agent æ± 
USER_AGENTS = [
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36",
    "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:122.0) Gecko/20100101 Firefox/122.0",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.2 Safari/605.1.15",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0"
]

def get_advanced_headers():
    """ç”Ÿæˆæ›´çœŸå¯¦çš„ headers"""
    return {
        "User-Agent": random.choice(USER_AGENTS),
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7",
        "Accept-Language": "en-US,en;q=0.9,zh-TW;q=0.8,zh;q=0.7",
        "Accept-Encoding": "gzip, deflate, br",
        "Connection": "keep-alive",
        "Upgrade-Insecure-Requests": "1",
        "Sec-Fetch-Dest": "document",
        "Sec-Fetch-Mode": "navigate",
        "Sec-Fetch-Site": "none",
        "Sec-Fetch-User": "?1",
        "Cache-Control": "max-age=0",
        "sec-ch-ua": '"Not A(Brand";v="99", "Google Chrome";v="121", "Chromium";v="121"',
        "sec-ch-ua-mobile": "?0",
        "sec-ch-ua-platform": '"Windows"'
    }

def add_smart_delay():
    """æ™ºæ…§å»¶é²ï¼Œé¿å…è¢«åµæ¸¬"""
    delay = random.uniform(2, 5)
    time.sleep(delay)

def get_channel_id(youtube_url):
    """å¾ YouTube URL æå–é »é“ ID"""
    handle = youtube_url.split("/")[-2] if "/@" in youtube_url else None
    if API_KEY and handle:
        try:
            url = f"https://www.googleapis.com/youtube/v3/channels?part=id&forHandle={handle}&key={API_KEY}"
            with httpx.Client(timeout=15) as client:
                res = client.get(url)
                res.raise_for_status()
                data = res.json()
                if data.get("items"):
                    print(f"âœ… API æ‰¾åˆ°é »é“ ID: {data['items'][0]['id']}")
                    return data["items"][0]["id"]
                print(f"âš ï¸ API ç„¡æ³•æ‰¾åˆ° {handle} çš„é »é“ IDï¼Œå˜—è©¦ HTML è§£æ")
        except Exception as e:
            print(f"âš ï¸ API ç²å–é »é“ ID å¤±æ•—: {e}")

    # HTML è§£æå‚™ç”¨æ–¹æ¡ˆ
    try:
        with httpx.Client(http2=True, follow_redirects=True, timeout=20) as client:
            headers = get_advanced_headers()
            add_smart_delay()
            res = client.get(youtube_url, headers=headers)
            html = res.text
            
            patterns = [
                r'"channelId":"(UC[^"]+)"',
                r'<meta itemprop="channelId" content="(UC[^"]+)"',
                r'"externalId":"(UC[^"]+)"',
                r'"browseId":"(UC[^"]+)"',
                r'channelId["\']:\s*["\']([^"\']+)["\']'
            ]
            
            for pattern in patterns:
                match = re.search(pattern, html)
                if match:
                    print(f"âœ… HTML æ‰¾åˆ°é »é“ ID: {match.group(1)}")
                    return match.group(1)
            
            print(f"âš ï¸ ç„¡æ³•å¾ {youtube_url} æå–é »é“ ID")
            return None
    except Exception as e:
        print(f"âš ï¸ HTML æå–é »é“ ID å¤±æ•—: {e}")
        return None

def get_live_video_id(channel_id):
    """ä½¿ç”¨ YouTube Data API ç²å–ç›´æ’­ videoId"""
    try:
        url = f"https://www.googleapis.com/youtube/v3/search?part=snippet&channelId={channel_id}&eventType=live&type=video&key={API_KEY}"
        with httpx.Client(timeout=15) as client:
            res = client.get(url)
            res.raise_for_status()
            data = res.json()
            if data.get("items"):
                video_id = data["items"][0]["id"]["videoId"]
                print(f"âœ… æ‰¾åˆ°ç›´æ’­ videoId: {video_id}")
                return f"https://www.youtube.com/watch?v={video_id}"
            print(f"âš ï¸ é »é“ {channel_id} ç›®å‰ç„¡ç›´æ’­ (API è¿”å›ç©ºçµæœ)")
            return None
    except Exception as e:
        print(f"âš ï¸ API è«‹æ±‚å¤±æ•—: {e}")
        return None

def extract_m3u8_from_html(html, url):
    """å¾ HTML ä¸­æå– m3u8 é€£çµï¼Œä½¿ç”¨å¤šç¨®æ–¹æ³•"""
    print(f"ğŸ” åˆ†æ HTML å…§å®¹ï¼Œé•·åº¦: {len(html)} å­—ç¬¦")
    
    # æ–¹æ³•1: å°‹æ‰¾ ytInitialPlayerResponse
    try:
        player_response_patterns = [
            r'ytInitialPlayerResponse\s*=\s*({.*?});',
            r'ytInitialPlayerResponse":\s*({.*?})(?:,"|$)',
            r'player_response["\']:\s*["\']([^"\']+)["\']'
        ]
        
        for pattern in player_response_patterns:
            match = re.search(pattern, html, re.DOTALL)
            if match:
                try:
                    if pattern.endswith(r'([^"\']+)["\']'):
                        # é€™æ˜¯ base64 ç·¨ç¢¼çš„æƒ…æ³
                        player_data = base64.b64decode(match.group(1)).decode('utf-8')
                        player_response = json.loads(player_data)
                    else:
                        player_response = json.loads(match.group(1))
                    
                    streaming_data = player_response.get("streamingData", {})
                    hls_url = streaming_data.get("hlsManifestUrl", "")
                    if hls_url:
                        print(f"âœ… å¾ ytInitialPlayerResponse æ‰¾åˆ° m3u8: {hls_url}")
                        return hls_url
                except (json.JSONDecodeError, Exception) as e:
                    print(f"âš ï¸ è§£æ player_response å¤±æ•—: {e}")
                    continue
    except Exception as e:
        print(f"âš ï¸ æœå°‹ ytInitialPlayerResponse å¤±æ•—: {e}")

    # æ–¹æ³•2: ç›´æ¥æœå°‹ m3u8 URL
    try:
        m3u8_patterns = [
            r'(https://[^"\'>\s]+\.m3u8[^"\'>\s]*)',
            r'"(https://[^"]+googlevideo\.com[^"]+\.m3u8[^"]*)"',
            r'\'(https://[^\']+googlevideo\.com[^\']+\.m3u8[^\']*)\''
        ]
        
        for pattern in m3u8_patterns:
            matches = re.findall(pattern, html)
            for match in matches:
                if "googlevideo.com" in match:
                    print(f"âœ… ç›´æ¥æ‰¾åˆ° m3u8 URL: {match}")
                    return match
    except Exception as e:
        print(f"âš ï¸ æœå°‹ m3u8 URL å¤±æ•—: {e}")

    # æ–¹æ³•3: å°‹æ‰¾ JavaScript è®Šæ•¸ä¸­çš„ä¸²æµè³‡è¨Š
    try:
        js_patterns = [
            r'streamingData["\']:\s*({[^}]+})',
            r'hlsManifestUrl["\']:\s*["\']([^"\']+)["\']',
            r'adaptiveFormats["\']:\s*\[([^\]]+)\]'
        ]
        
        for pattern in js_patterns:
            matches = re.findall(pattern, html)
            for match in matches:
                if "googlevideo.com" in match and ".m3u8" in match:
                    # å˜—è©¦æå– URL
                    url_match = re.search(r'https://[^"\'>\s]+\.m3u8[^"\'>\s]*', match)
                    if url_match:
                        print(f"âœ… å¾ JavaScript è®Šæ•¸æ‰¾åˆ° m3u8: {url_match.group()}")
                        return url_match.group()
    except Exception as e:
        print(f"âš ï¸ æœå°‹ JavaScript è®Šæ•¸å¤±æ•—: {e}")

    # æ–¹æ³•4: æª¢æŸ¥æ˜¯å¦æœ‰å…§åµŒçš„ player
    try:
        embed_patterns = [
            r'embed/([a-zA-Z0-9_-]+)',
            r'watch\?v=([a-zA-Z0-9_-]+)'
        ]
        
        for pattern in embed_patterns:
            match = re.search(pattern, url)
            if match:
                video_id = match.group(1)
                print(f"ğŸ” å˜—è©¦ç›´æ¥è¨ªå• video ID: {video_id}")
                return get_m3u8_from_video_id(video_id)
    except Exception as e:
        print(f"âš ï¸ æª¢æŸ¥å…§åµŒ player å¤±æ•—: {e}")

    print("âš ï¸ æ‰€æœ‰æ–¹æ³•éƒ½æœªæ‰¾åˆ°æœ‰æ•ˆçš„ m3u8 é€£çµ")
    return None

def get_m3u8_from_video_id(video_id):
    """ç›´æ¥å¾ video ID ç²å– m3u8"""
    try:
        video_url = f"https://www.youtube.com/watch?v={video_id}"
        with httpx.Client(http2=True, follow_redirects=True, timeout=20) as client:
            headers = get_advanced_headers()
            
            # è¼‰å…¥ cookies
            cookies = load_cookies()
            
            add_smart_delay()
            res = client.get(video_url, headers=headers, cookies=cookies)
            html = res.text
            
            return extract_m3u8_from_html(html, video_url)
    except Exception as e:
        print(f"âš ï¸ å¾ video ID ç²å– m3u8 å¤±æ•—: {e}")
        return None

def load_cookies():
    """è¼‰å…¥ cookies"""
    cookies = {}
    if os.path.exists(cookies_path):
        try:
            with open(cookies_path, "r", encoding="utf-8") as f:
                for line in f:
                    if not line.startswith('#') and '\t' in line:
                        parts = line.strip().split('\t')
                        if len(parts) >= 7:
                            cookies[parts[5]] = parts[6]
            print(f"âœ… è¼‰å…¥äº† {len(cookies)} å€‹ cookies")
        except Exception as e:
            print(f"âš ï¸ Cookie è®€å–å¤±æ•—: {e}")
    return cookies

def grab_with_multiple_methods(youtube_url):
    """ä½¿ç”¨å¤šç¨®æ–¹æ³•å˜—è©¦æŠ“å– m3u8"""
    methods = [
        ("å„ªåŒ–ç„¡ Cookie æ–¹å¼", lambda url: grab_optimized(url, use_cookies=False)),
        ("å„ªåŒ– Cookie æ–¹å¼", lambda url: grab_optimized(url, use_cookies=True)),
        ("API è¼”åŠ©å„ªåŒ–æ–¹å¼", grab_with_api_enhanced)
    ]
    
    for method_name, method_func in methods:
        print(f"ğŸ”„ å˜—è©¦ {method_name}")
        try:
            result = method_func(youtube_url)
            if result and "googlevideo.com" in result and ".m3u8" in result:
                print(f"âœ… {method_name} æˆåŠŸ")
                return result
            else:
                print(f"âš ï¸ {method_name} å¤±æ•—")
        except Exception as e:
            print(f"âŒ {method_name} ç™¼ç”ŸéŒ¯èª¤: {e}")
        
        add_smart_delay()
    
    print("âŒ æ‰€æœ‰æ–¹æ³•éƒ½å¤±æ•—ï¼Œä½¿ç”¨å‚™ç”¨é€£çµ")
    return "https://raw.githubusercontent.com/jz168k/YT2m/main/assets/no_s.m3u8"

def grab_optimized(youtube_url, use_cookies=False):
    """å„ªåŒ–çš„æŠ“å–æ–¹æ³•"""
    try:
        with httpx.Client(http2=True, follow_redirects=True, timeout=30) as client:
            headers = get_advanced_headers()
            
            cookies = {}
            if use_cookies:
                cookies = load_cookies()
            
            print(f"ğŸŒ è¨ªå• URL: {youtube_url}")
            add_smart_delay()
            
            res = client.get(youtube_url, headers=headers, cookies=cookies)
            html = res.text
            
            # æª¢æŸ¥æ˜¯å¦ç‚ºç›´æ’­
            if any(indicator in html.lower() for indicator in ['noindex', 'offline', 'not available', 'this live stream recording is not available']):
                print(f"âš ï¸ ç›´æ’­ä¸å¯ç”¨æˆ–é›¢ç·š: {youtube_url}")
                return None
            
            # ä½¿ç”¨å¢å¼·çš„ m3u8 æå–
            m3u8_url = extract_m3u8_from_html(html, youtube_url)
            return m3u8_url
            
    except Exception as e:
        print(f"âš ï¸ å„ªåŒ–æŠ“å–å¤±æ•—: {e}")
        return None

def grab_with_api_enhanced(youtube_url):
    """ä½¿ç”¨ API è¼”åŠ©çš„å¢å¼·æ–¹å¼"""
    if not API_KEY:
        print("âš ï¸ æ²’æœ‰ API é‡‘é‘°ï¼Œè·³é API è¼”åŠ©æ–¹å¼")
        return None
    
    try:
        # æå–é »é“ ID
        channel_id = get_channel_id(youtube_url)
        if not channel_id:
            return None
        
        # ä½¿ç”¨ API ç²å–ç›´æ’­ URL
        live_url = get_live_video_id(channel_id)
        if not live_url:
            return None
        
        # ä½¿ç”¨å„ªåŒ–æ–¹å¼æŠ“å–
        return grab_optimized(live_url, use_cookies=True)
        
    except Exception as e:
        print(f"âš ï¸ API è¼”åŠ©å¢å¼·æ–¹å¼å¤±æ•—: {e}")
        return None

def process_yt_info():
    """è™•ç† YouTube è³‡è¨Š"""
    print(f"ğŸ“– è®€å– {yt_info_path}")
    try:
        with open(yt_info_path, "r", encoding="utf-8") as f:
            lines = f.readlines()
    except Exception as e:
        print(f"âŒ è®€å– {yt_info_path} å¤±æ•—: {e}")
        return

    i = 1
    success_count = 0
    total_count = 0
    
    for line in lines:
        line = line.strip()
        if line.startswith("~~") or not line:
            continue
            
        total_count += 1
        
        if "|" in line:
            parts = line.split("|")
            channel_name = parts[0].strip() if len(parts) > 0 else f"Channel {i}"
            youtube_url = parts[1].strip() if len(parts) > 1 else ""
        else:
            youtube_url = line
            channel_name = f"Channel {i}"
        
        if not youtube_url:
            continue
            
        print(f"\nğŸ” [{i:02d}] è™•ç†: {channel_name}")
        print(f"ğŸ”— URL: {youtube_url}")

        # ä½¿ç”¨å¤šç¨®æ–¹æ³•å˜—è©¦æŠ“å–
        m3u8_url = grab_with_multiple_methods(youtube_url)
        
        if m3u8_url and "googlevideo.com" in m3u8_url:
            success_count += 1
            print(f"âœ… æˆåŠŸç²å– m3u8")
        else:
            print(f"âš ï¸ ä½¿ç”¨å‚™ç”¨é€£çµ")

        # ç”Ÿæˆ m3u8 æ–‡ä»¶
        m3u8_content = f"#EXTM3U\n#EXT-X-STREAM-INF:BANDWIDTH=1280000\n{m3u8_url}\n"
        output_m3u8 = os.path.join(output_dir, f"y{i:02d}.m3u8")
        with open(output_m3u8, "w", encoding="utf-8") as f:
            f.write(m3u8_content)

        # ç”Ÿæˆ PHP æ–‡ä»¶
        php_content = f"""<?php
header('Location: {m3u8_url}');
?>"""
        output_php = os.path.join(output_dir, f"y{i:02d}.php")
        with open(output_php, "w", encoding="utf-8") as f:
            f.write(php_content)

        print(f"ğŸ“ ç”Ÿæˆ {output_m3u8} å’Œ {output_php}")
        i += 1
        
        # è™•ç†é–“éš”
        if i <= total_count:
            add_smart_delay()
    
    print(f"\nğŸ“Š è™•ç†å®Œæˆçµ±è¨ˆ:")
    print(f"   ç¸½è¨ˆ: {total_count} å€‹é »é“")
    print(f"   æˆåŠŸ: {success_count} å€‹")
    print(f"   å¤±æ•—: {total_count - success_count} å€‹")
    print(f"   æˆåŠŸç‡: {(success_count/total_count*100):.1f}%")

def upload_files():
    """ä¸Šå‚³æª”æ¡ˆåˆ° SFTP"""
    print("ğŸš€ å•Ÿå‹• SFTP ä¸Šå‚³ç¨‹åº...")
    try:
        transport = paramiko.Transport((SFTP_HOST, SFTP_PORT))
        transport.connect(username=SFTP_USER, password=SFTP_PASSWORD)
        sftp = paramiko.SFTPClient.from_transport(transport)

        print(f"âœ… æˆåŠŸé€£æ¥åˆ° SFTPï¼š{SFTP_HOST}")

        try:
            sftp.chdir(SFTP_REMOTE_DIR)
        except IOError:
            print(f"ğŸ“ é ç«¯ç›®éŒ„ {SFTP_REMOTE_DIR} ä¸å­˜åœ¨ï¼Œæ­£åœ¨å‰µå»º...")
            sftp.mkdir(SFTP_REMOTE_DIR)
            sftp.chdir(SFTP_REMOTE_DIR)

        upload_count = 0
        for file in os.listdir(output_dir):
            local_path = os.path.join(output_dir, file)
            remote_path = os.path.join(SFTP_REMOTE_DIR, file)
            if os.path.isfile(local_path):
                print(f"â¬†ï¸ ä¸Šå‚³ {local_path} â†’ {remote_path}")
                sftp.put(local_path, remote_path)
                upload_count += 1

        sftp.close()
        transport.close()
        print(f"âœ… SFTP ä¸Šå‚³å®Œæˆï¼å…±ä¸Šå‚³ {upload_count} å€‹æª”æ¡ˆ")

    except Exception as e:
        print(f"âŒ SFTP ä¸Šå‚³å¤±æ•—: {e}")

if __name__ == "__main__":
    print("ğŸ¬ YouTube M3U8 è§£æå™¨å•Ÿå‹•")
    print(f"â° é–‹å§‹æ™‚é–“: {datetime.now()}")
    
    try:
        process_yt_info()
        upload_files()
    except KeyboardInterrupt:
        print("\nâ¹ï¸ ç¨‹åºè¢«ç”¨æˆ¶ä¸­æ–·")
    except Exception as e:
        print(f"âŒ ç¨‹åºåŸ·è¡Œå¤±æ•—: {e}")
    finally:
        print(f"â° çµæŸæ™‚é–“: {datetime.now()}")
        print("ğŸ ç¨‹åºçµæŸ")
